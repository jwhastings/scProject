---
title: "Seurat Integration (Dataset 3)"
author: "Joey Hastings"
date: "`r Sys.Date()`"
output:
  rmdformats::html_clean:
    highlight: kate
    thumbnails: FALSE
    toc_depth: 2
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  fig.align = "center",
  fig.dim = c(9, 6)
  )
```

# Load Packages

```{r, message = FALSE}
library(tictoc)
library(tidyverse)
library(cowplot)
library(ggExtra)
library(ggthemes)

library(splatter)
library(scater)
library(scran)
library(r.jive)
library(Seurat)
library(factoextra)
library(SLIDE)
library(RSpectra)

library(kBET) # kBET
library(cluster) # ASW
library(lisi) # LISI
library(mclust) # ARI

theme_set(theme_few())

method_name <- "Seurat"
dataset_name <- "dataset3"
```

# Simulation 1

## Generate Cell Counts

* Three cell types/groups (unbalanced)
* Two batches (balanced)
* Small dropout

```{r}
# Parameters that remain the same for all cell types
nGenes <- 5000
method = "single"
dropout.type = "experiment"
dropout.shape = -1
verbose = FALSE
```

```{r}
tic("Data Simulation")
sim1 <- splatSimulate(
  # Parameters to remain the same
  verbose = verbose,
  batchCells = c(500, 500),
  dropout.mid = 0.05,
  nGenes = nGenes,
  method = "groups",
  seed = 1,
  dropout.type = dropout.type,
  dropout.shape = dropout.shape,
  group.prob = c(0.6, 0.3, 0.1),
  # Parameters to tweak in each simulation
  batch.facLoc = 0.2,
  batch.facScale = 0.1,
  de.prob = c(0.01, 0.1, 0.5),
  de.downProb = c(0.01, 0.4, 0.9),
  de.facLoc = c(0.6, 1, 0.2),
  de.facScale = c(0.1, 0.4, 0.8),
  bcv.common = 1
)
toc()
```

```{r}
sim1 <- logNormCounts(sim1)
sim1 <- addPerCellQC(sim1)
n.features <- colData(sim1)$detected
colData(sim1)$PctZero <- 100 * (1 - n.features/nrow(sim1))

# Dimension reduction visualization
set.seed(1)
sim1 <- runPCA(sim1, ncomponents = 30, ntop = 2000)
sim1 <- runTSNE(sim1)
sim1 <- runUMAP(sim1)
orig_p1 <- plotPCA(sim1, color_by = "Batch", shape_by = "Group")
orig_p2 <- plotTSNE(sim1, color_by = "Batch", shape_by = "Group")
orig_p3 <- plotUMAP(sim1, color_by = "Batch", shape_by = "Group")

orig_p1
orig_p2
orig_p3
```

## Separate Batches

```{r}
batches <- sim1$Batch
# Frequency of batches in simulation
table(batches)

groups <- sim1$Group
# Frequency of cell types in simulation
table(groups)

rawcounts <- counts(sim1)
dim(rawcounts)

b1 <- rawcounts[, batches == "Batch1"]
grp_b1 <- groups[batches == "Batch1"]
# Dimension of batch 1
dim(b1)
# Frequency of cell types in batch 1
table(grp_b1)

b2 <- rawcounts[, batches == "Batch2"]
grp_b2 <- groups[batches == "Batch2"]
# Dimension of batch 2
dim(b2)
# Frequency of cell types in batch 2
table(grp_b2)
```

# Seurat

Perform cell batch integration as in their tutorial.

## Setup

* Create Seurat objects for each batch
  * Assign metadata to each object (batch number, cell type)
* Normalize the cell counts
* Identify most variable features (genes) 
* Choose most variable features from both batches for use in integration

```{r}
b1_seurat <- CreateSeuratObject(counts = b1, project = "simulation")
b1_seurat <- AddMetaData(b1_seurat, "Batch1", col.name = "BatchNum")
b1_seurat <- AddMetaData(b1_seurat, grp_b1, col.name = "Group")

b2_seurat <- CreateSeuratObject(counts = b2, project = "simulation")
b2_seurat <- AddMetaData(b2_seurat, "Batch2", col.name = "BatchNum")
b2_seurat <- AddMetaData(b2_seurat, grp_b2, col.name = "Group")

seurat_list <- list(Batch1 = b1_seurat, Batch2 = b2_seurat)

# normalize and identify variable features for each dataset independently
seurat_list <- lapply(X = seurat_list, FUN = function(x) {
    x <- NormalizeData(x)
    x <- FindVariableFeatures(x, selection.method = "vst", nfeatures = 5000)
})

# select features that are repeatedly variable across datasets for integration
features <- SelectIntegrationFeatures(object.list = seurat_list, nfeatures = 5000)
```

## Integration

* Perform integration by finding a set of anchors from the two batches (via CCA)
* Use the anchor list to integrate the two batches

```{r}
anchors <- FindIntegrationAnchors(object.list = seurat_list, anchor.features = features)
combined <- IntegrateData(anchorset = anchors)
GetAssay(combined, "integrated")
```

## Integrated Analysis

* Integrated/combined data is centered/scaled
* First 30 PCs are computed/stored
* PC1-PC30 are used to perform t-SNE and UMAP dimensionality reduction
* Calculates k-nearest neighbors (`k = 20` by default) from PC1-PC30
* Identify clusters by using Shared Nearest Neighbors (SNN):
  * "First calculate k-nearest neighbors and construct the SNN graph"
  * "Then optimize the modularity function to determine clusters"

```{r}
# specify that we will perform downstream analysis on the corrected data note that the
# original unmodified data still resides in the 'RNA' assay
DefaultAssay(combined) <- "integrated"

# Run the standard workflow for visualization and clustering
set.seed(1)
combined <- ScaleData(combined, verbose = FALSE)
combined <- RunPCA(combined, npcs = 30, verbose = FALSE)
combined <- RunTSNE(combined, reduction = "pca", dims = 1:30)
combined <- RunUMAP(combined, reduction = "pca", dims = 1:30)
combined <- FindNeighbors(combined, reduction = "pca", dims = 1:30)
combined <- FindClusters(combined, resolution = 0.5)
```

Visualize integrated batches and clusters using UMAP:

```{r}
# Visualization
dr1 <- DimPlot(combined, reduction = "pca", group.by = "BatchNum", shape.by = "Group")
dr2 <- DimPlot(combined, reduction = "tsne", group.by = "BatchNum", shape.by = "Group", pt.size = 1.5)
dr3 <- DimPlot(combined, reduction = "umap", group.by = "BatchNum", shape.by = "Group", pt.size = 1.5)

plots <- align_plots(dr1, dr2, align = 'v', axis = 'l')
# then build the bottom row
bottom_row <- plot_grid(plots[[2]], dr3, labels = c('B', 'C'), label_size = 12)

# then combine with the top row for final plot
dr_all <- plot_grid(plots[[1]], bottom_row, labels = c('A', ''), label_size = 12, ncol = 1)
dr_all

# Frequency of true cell types/groups vs. identified clusters
table(combined@meta.data[, c("Group", "seurat_clusters")])
```

```{r}
seurat_final <- t(as.matrix(GetAssay(combined, "integrated")@data))
```

# Calculate kBET

* Sub-sample data at varying percentages
  * 5%, 10%, 15%, 20%, 25%
  * Stratified sampling so that each batch has the same number of cells selected
    * E.g., assume 2 batches, sampling 10% of 1000 cells = 100 cells: sample 50 cells from each batch
* Calculate kBET rejection rates at each percentage
  * **Lower** RR indicate well-mixed batches
  * **Higher** RR indicate poorly-mixed batches
  
```{r}
# data: a matrix (rows: samples, columns: features (genes))
data <- combined@reductions$pca@cell.embeddings

# batch: vector or factor with batch label of each cell 
batch <- combined$BatchNum

sample_size <- seq(0.05, 0.25, by = 0.05)
rejection_rate <- list()

set.seed(1)
for (i in 1:length(sample_size)) {
  k <- floor(nrow(data) * sample_size[i])
  
  batch.estimate <- kBET(data, batch, k0 = k, plot = F, do.pca = F, verbose = T)
  
  if (class(batch.estimate) == "list") {
    rejection_rate[[i]] <- batch.estimate$summary %>%
      rownames_to_column(var = "statistic") %>%
      mutate(sample_size = sample_size[i]) %>%
      select(sample_size, statistic, kBET_rr = kBET.observed)
  }
}

all_rr <- bind_rows(rejection_rate) %>%
  mutate(method = method_name) %>%
  pivot_wider(id_cols = c(method, sample_size), names_from = statistic, values_from = kBET_rr) %>%
  select(method, sample_size, median_rr = `50%`)

all_rr %>% write_csv(file = paste0("output/", method_name, "_", dataset_name, "_kBET.csv"))

all_rr %>%
  ggplot(aes(x = sample_size, y = median_rr)) + 
  geom_line(linewidth = 1) +
  geom_point() +
  scale_x_continuous(labels = scales::percent) +
  expand_limits(y = c(0, 1)) + 
  labs(
    x = "% sample size",
    y = "kBET (rejection rate)",
    color = "Cell Group",
    title = "kBET Rejection Rates",
    subtitle = method_name
  )

all_rr %>%
  ggplot(aes(x = sample_size, y = I(1 - median_rr))) + 
  geom_line(linewidth = 1) +
  geom_point() +
  scale_x_continuous(labels = scales::percent) +
  expand_limits(y = c(0, 1)) + 
  labs(
    x = "% sample size",
    y = "kBET (acceptance rate)",
    color = "Cell Group",
    title = "kBET Acceptance Rates",
    subtitle = method_name
  )
```

# Calculate Average Silhouette Width

Original batch label and cell types/groups will be considered the clusters to compute $ASW_{batch}$ and $ASW_{group}$

* Compute average silhouette width (ASW) for the first 30 PCs of 80% sub-sample of joint data
  * ASW ranges between -1 and 1
  * Values **close to 1** indicate the cell is well-matched to its cluster (i.e., batch label)
  * Values **close to -1** indicate the cell is **not** well-matched to its cluster (i.e., batch label)
    * We hope to see lower values for $ASW_{batch}$ since it is indicative of well-mixed batches
    * We hope to see higher values for $ASW_{group}$ since it is indicative that distinct cell groups were preserved after batch-mixing
* Repeat `20` times
* Calculate the median ASW from the `20` runs to ensure stability of the measurement

```{r}
asw_repeat <- 20
npcs <- 30

asw_batch <- list()
asw_group <- list()
subset_prop <- 0.8 # subsample to 80% of the data
subset_size_total <- floor(length(batch) * subset_prop)

set.seed(1)
for (i in 1:asw_repeat) {
  subset_index <- 
    data.frame(index = 1:length(batch) , batch = batch) %>%
    slice_sample(n = subset_size_total, replace = F)
  
  subset_id <- subset_index %>%
    pull(index)
  
  data_pc <- svds(seurat_final[subset_id, ], k = npcs)$u
  
  dissimilarity_matrix <- daisy(data_pc)
  
  asw_batch_i <- silhouette(as.integer(factor(batches[subset_id])), dissimilarity_matrix)
  asw_batch[[i]] <- as.data.frame(rbind(summary(asw_batch_i)[["si.summary"]]))
  
  asw_group_i <- silhouette(as.integer(factor(groups[subset_id])), dissimilarity_matrix)
  asw_group[[i]] <- as.data.frame(rbind(summary(asw_group_i)[["si.summary"]]))
}

all_asw_batch <- bind_rows(asw_batch) %>%
  mutate(Cluster = "Batch")

# ASW_batch summary
summary(all_asw_batch$Mean)

all_asw_group <- bind_rows(asw_group) %>%
  mutate(Cluster = "Group")

#ASW_group summary
summary(all_asw_group$Mean)

all_asw <- bind_rows(all_asw_batch, all_asw_group)

asw_plot <- ggplot(data = all_asw, aes(x = Cluster, y = Mean, fill = Cluster)) +
  geom_violin() +
  geom_boxplot(width = 0.2)

asw_plot

all_asw %>%
  group_by(Cluster) %>%
  mutate(Method = method_name) %>%
  write_csv(file = paste0("output/", method_name, "_", dataset_name, "_ASW.csv"))
```

# Calculate LISI Scores

```{r}
# Performed for all cells

lisi <- compute_lisi(seurat_final, data.frame(batch = batches, group = groups), c("batch", "group"), perplexity = 40) %>%
  pivot_longer(cols = c("batch", "group"), names_to = "type", values_to = "lisi")

# Looking for values close to the number of batches (2)
# Looking for values close to 1

ggplot(data = lisi, aes(x = type, y = lisi, fill = type)) +
  geom_violin() +
  geom_boxplot(width = 0.05)
```

<!-- ### Calculate Adjusted Rand Index -->

<!-- * Compute adjusted rand index (ARI) for a 80% sub-sample of clusters -->
<!--   * ARI is bounded above by 1 (i.e., perfect agreement between two partitions) -->
<!--   * Values **close to 1** indicate the two partition labels are similar -->
<!--   * Values **close to 0** indicate the two partition labels are not similar -->
<!--     * We hope to see lower values for $ARI_{batch}$ since it is indicative of well-mixed batches -->
<!--     * We hope to see higher values for $ARI_{group}$ since it is indicative that distinct cell groups were preserved after batch-mixing -->
<!-- * Repeat `20` times -->
<!-- * Calculate the median ARI from the `20` runs to ensure stability of the measurement -->

<!-- ```{r jive_ari} -->
<!-- ari_repeat <- 20 -->
<!-- npcs <- 30 -->

<!-- ari_batch <- list() -->
<!-- ari_group <- list() -->
<!-- subset_prop <- 0.8 # subsample to 80% of the data -->
<!-- subset_size_total <- floor(length(batch) * subset_prop) -->

<!-- set.seed(1) -->
<!-- for (i in 1:ari_repeat) { -->
<!--   subset_index <-  -->
<!--     data.frame(index = 1:length(batch) , batch = batch) %>% -->
<!--     slice_sample(n = subset_size_total, replace = F) -->

<!--   subset_id <- subset_index %>% -->
<!--     pull(index) -->

<!--   clusters <- kmeans(svd(joint[subset_id, ])$u, centers = length(unique(groups)))$cluster -->

<!--   ari_batch[[i]] <- adjustedRandIndex(factor(batches[subset_id]), clusters[subset_id]) -->
<!--   ari_group[[i]] <- adjustedRandIndex(factor(groups[subset_id]), clusters[subset_id]) -->
<!-- } -->

<!-- all_ari_batch <- data.frame(ari = unlist(ari_batch)) %>% -->
<!--   mutate(cluster = "Batch") -->

<!-- # Lower values indicate well-mixed batches -->
<!-- summary(all_ari_batch$ari) -->

<!-- all_ari_group <- data.frame(ari = unlist(ari_group)) %>% -->
<!--   mutate(cluster = "Group")  -->

<!-- # Higher values indicate cell types were well preserved -->
<!-- summary(all_ari_group$ari) -->

<!-- all_ari <- bind_rows(all_ari_batch, all_ari_group) -->

<!-- ari_plot <- ggplot(data = all_ari, aes(x = cluster, y = ari, fill = cluster)) + -->
<!--   geom_violin() + -->
<!--   geom_boxplot(width = 0.2) -->

<!-- ari_plot -->
<!-- ``` -->

# Session Information

```{r session_info}
sessionInfo()
```
