---
title: "Splatter Simulation and JIVE Integration"
author: "Joey Hastings"
date: "`r Sys.Date()`"
output:
  rmdformats::html_clean:
    highlight: kate
    thumbnails: FALSE
    toc_depth: 2
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  fig.align = "center",
  fig.dim = c(9, 6)
  )
```

# Load Packages

```{r load_packages, message = FALSE}
library(tictoc)
library(tidyverse)
library(cowplot)
library(ggExtra)
library(ggthemes)

library(splatter)
library(scater)
library(scran)
library(r.jive)
library(Seurat)
library(factoextra)
library(SLIDE)
library(cluster)

library(kBET)
library(lisi)
```

# Simulation 1

## Generate Cell Counts

* Three cell types/groups (unbalanced)
* Two batches (balanced)
* Small dropout

```{r sim1_param_spec}
# Parameters that remain the same for all cell types
nGenes <- 5000
method = "single"
dropout.type = "experiment"
dropout.shape = -1
verbose = FALSE
```

```{r sim1_simultaneous}
tic("Data Simulation")
sim1 <- splatSimulate(
  # Parameters to tweak in each simulation
  batchCells = c(500, 500),
  batch.facLoc = c(0.001, 0.5),
  batch.facScale = c(0.001, 0.5),
  dropout.mid = 0.05,
  # Parameters to remain the same
  nGenes = nGenes,
  method = "groups",
  seed = 1,
  dropout.type = dropout.type,
  dropout.shape = dropout.shape,
  group.prob = c(0.6, 0.3, 0.1),
  de.prob = c(0.01, 0.1, 0.5),
  de.downProb = c(0.01, 0.4, 0.9),
  de.facLoc = c(0.6, 1, 0.2),
  de.facScale = c(0.1, 0.4, 0.8),
  verbose = verbose
  )
toc()
```

```{r sim1_viz}
sim1 <- logNormCounts(sim1)

# Dimension reduction visualization
set.seed(1)
sim1 <- runPCA(sim1, ncomponents = 30, ntop = 2000)
orig_p1 <- plotPCA(sim1, color_by = "Batch", shape_by = "Group")
orig_p1
```

## Separate Batches

```{r sim1_batches}
batches <- sim1$Batch
# Frequency of batches in simulation
table(batches)

groups <- sim1$Group
# Frequency of cell types in simulation
table(groups)

rawcounts <- counts(sim1)
dim(rawcounts)

b1 <- rawcounts[, batches == "Batch1"]
grp_b1 <- groups[batches == "Batch1"]
# Dimension of batch 1
dim(b1)
# Frequency of cell types in batch 1
table(grp_b1)

b2 <- rawcounts[, batches == "Batch2"]
grp_b2 <- groups[batches == "Batch2"]
# Dimension of batch 2
dim(b2)
# Frequency of cell types in batch 2
table(grp_b2)
```

## Compare Batches

```{r sim1_batches_comp}
# Convert count matrices for batch 1 and 2 in to SCE objects for comparison via splatter
b1_sce <- SingleCellExperiment(list(counts = b1))
b2_sce <- SingleCellExperiment(list(counts = b2))

comparison <- compareSCEs(
  list(
    Batch1 = b1_sce,
    Batch2 = b2_sce
    )
  )

plot_grid(plotlist = comparison$Plots[1:4])
plot_grid(plotlist = comparison$Plots[5:8])
```

## JIVE

This time we transpose the matrices so that the common genes ($n$ = `r nGenes`) are the columns and the cells are the rows:

```{r jive1, eval = FALSE}
#```{r jive1}
sim1_data <- NULL
sim1_data$Batch1 <- t(b1)
sim1_data$Batch2 <- t(b2)

set.seed(1)

# Permutation
tic("JIVE Analysis (Permutation)")
JIVE_results_default <- jive(sim1_data, rankJ = 2, rankA = c(3, 3))
toc()

saveRDS(JIVE_results_default, file = "data/JIVE_results2_perm.rds")

# BIC
# tic("JIVE Analysis (BIC)")
# JIVE_results_bic <- jive(sim1_data, method = "bic") # did not converge over multiple days
# toc()
# 
# saveRDS(JIVE_results_bic, file = "data/JIVE_results2_bic.rds")
```

Summary of estimated ranks and variance explained by joint/individual/residual for each approach:

```{r jive1_summary}
JIVE_results_default <- readRDS(file = "data/JIVE_results2_perm.rds")
summary(JIVE_results_default)

# JIVE_results_bic <- readRDS(file = "JIVE_results2_bic.rds")
# summary(JIVE_results_bic)
```

### Visualization using PCA

Visualize the principal components of the joint portion of the JIVE decomposition:

```{r jive1_viz}
JIVE_results <- JIVE_results_default

# showPCA(JIVE_results, 2)

joint <- do.call(rbind, JIVE_results$joint)

# PCA
# joint_prcomp <- prcomp(joint, scale. = T)
# joint_pc <- joint_prcomp[["x"]] %>%
#   as.data.frame() %>%
#   select(PC1, PC2) %>%
#   mutate(
#     Batch = batches,
#     Group = c(grp_b1, grp_b2)
#   )
# 
# pc1_var_expl <- round(summary(joint_prcomp)[["importance"]][2, 1] * 100, digits = 1)
# pc2_var_expl <- round(summary(joint_prcomp)[["importance"]][2, 2] * 100, digits = 1)

# SVD
joint_svd <- svd(joint)
joint_pc <- joint_svd$u %>%
  as.data.frame() %>%
  select(PC1 = V1, PC2 = V2) %>%
  mutate(
    Batch = batches,
    Group = c(grp_b1, grp_b2)
  )

# https://genomicsclass.github.io/book/pages/pca_svd.html
svd_var_expl <- joint_svd$d^2 / sum(joint_svd$d^2)
pc1_var_expl <- round(svd_var_expl[1] * 100, digits = 1)
pc2_var_expl <- round(svd_var_expl[2] * 100, digits = 1)

# Plot
p <- ggplot(data = joint_pc) +
  geom_point(
    aes(x = PC1, y = PC2, color = Batch, shape = Group),
    alpha = 0.5, size = 2
  ) +
  labs(
    x = paste0("PC1 (", pc1_var_expl, "%)"),
    y = paste0("PC2 (", pc2_var_expl, "%)")
    ) +
  scale_color_few() +
  #scale_color_brewer(palette = "Dark2") +
  theme_few() +
  theme(legend.position = "bottom") 

marg_p <- ggMarginal(p, type = "density", groupColour = TRUE, groupFill = TRUE)
marg_p
```

### Visualization using `SCE`

```{r jive1_clust1}
JIVE_joint_b1_SCE <- SingleCellExperiment(list(logcounts = t(JIVE_results[["joint"]][[1]])))
colData(JIVE_joint_b1_SCE)$Group <- grp_b1
colData(JIVE_joint_b1_SCE)$BatchNum <- "Batch1"

JIVE_joint_b2_SCE <- SingleCellExperiment(list(logcounts = t(JIVE_results[["joint"]][[2]])))
colData(JIVE_joint_b2_SCE)$Group <- grp_b2
colData(JIVE_joint_b2_SCE)$BatchNum <- "Batch2"

JIVE_joint_SCE <- cbind(JIVE_joint_b1_SCE, JIVE_joint_b2_SCE)

set.seed(1)
JIVE_joint_SCE <- runPCA(JIVE_joint_SCE, ncomponents = 30, ntop = 2000)
# JIVE_joint_SCE <- runTSNE(JIVE_joint_SCE)
# JIVE_joint_SCE <- runUMAP(JIVE_joint_SCE)

clusters <- clusterCells(
  JIVE_joint_SCE,
  use.dimred = "PCA",
  BLUSPARAM = bluster::SNNGraphParam(
    cluster.fun = "louvain", 
    cluster.args = list(resolution = 0.5)
    )
  )

colData(JIVE_joint_SCE)$Cluster <- clusters

# By Batch/Group
jive_p1 <- plotPCA(JIVE_joint_SCE, color_by = "BatchNum", shape_by = "Group")
jive_p1

# By Batch/Cluster
jive_p2 <- plotPCA(JIVE_joint_SCE, color_by = "Cluster", shape_by = "Group")
jive_p2
```

### Calculate kBET

* Sub-sample data at varying percentages
  * 5%, 10%, 15%, 20%, 25%
  * Stratified sampling so that each batch has the same number of cells selected
    * E.g., assume 2 batches, sampling 10% of 1000 cells = 100 cells: sample 50 cells from each batch
* Calculate kBET rejection rates at each percentage
  * **Lower** RR indicate well-mixed batches
  * **Higher** RR indicate poorly-mixed batches
  
```{r jive_kbet}
# data: a matrix (rows: samples, columns: features (genes))
data <- joint

# batch: vector or factor with batch label of each cell 
batch <- batches

sample_size <- seq(0.05, 0.25, 0.05)
rejection_rate <- list()

set.seed(1)
for (i in sample_size) {
  subset_prop <- i # subsample to 10% of the data
  subset_size_total <- floor(length(batch) * subset_prop)
  subset_size_per_batch <- floor(subset_size_total / length(unique(batch)))
  
  subset_index <- 
    data.frame(index = 1:length(batch) , batch = batch) %>%
    group_by(batch) %>%
    slice_sample(n = subset_size_per_batch, replace = F)
  
  table(subset_index$batch)
  
  subset_id <- subset_index %>%
    pull(index)
  
  batch.estimate <- kBET(data[subset_id,], batch[subset_id], plot = F)
  
  rejection_rate[[which(sample_size == i)]] <- batch.estimate$summary %>%
    rownames_to_column(var = "statistic") %>%
    mutate(sample_size = i, n_batch = subset_size_per_batch) %>%
    select(sample_size, n_batch, statistic, kBET_rr = kBET.observed)
}

all_rr <- bind_rows(rejection_rate) %>%
  pivot_wider(id_cols = c(sample_size, n_batch), names_from = statistic, values_from = kBET_rr)

all_rr %>%
  ggplot(aes(x = sample_size, y = mean)) +
  geom_line(aes(y = `97.5%`), color = "darkgray", linetype = "dashed") +
  geom_line(aes(y = `2.5%`), color = "darkgray", linetype = "dashed") +
  geom_line() +
  # geom_line(aes(y = `97.5%`), color = "darkgray") +
  geom_linerange(aes(ymin = `2.5%`, ymax = `97.5%`), color = "darkgray", linetype = "dashed") +
  geom_point() +
  scale_x_continuous(labels = scales::percent) +
  labs(x = "% sample size", y = "kBET (rejection rate)")
```

### Calculate Average Silhouette Width

Original batch label and cell types/groups will be considered the clusters to compute $ASW_{batch}$ and $ASW_{group}$

* Compute average silhouette width (ASW) for the first 30 PCs of 80% sub-sample of joint data
  * ASW ranges between -1 and 1
  * Values **close to 1** indicate the cell is well-matched to its cluster (i.e., batch label)
  * Values **close to -1** indicate the cell is **not** well-matched to its cluster (i.e., batch label)
    * We hope to see lower values for $ASW_{batch}$ since it is indicative of well-mixed batches
    * We hope to see higher values for $ASW_{group}$ since it is indicative that distinct cell groups were preserved after batch-mixing
* Repeat `20` times
* Calculate the median ASW from the `20` runs to ensure stability of the measurement

```{r jive_asw}
asw_repeat <- 20
npcs <- 30

asw_batch <- list()
asw_group <- list()
subset_prop <- 0.8 # subsample to 80% of the data
subset_size_total <- floor(length(batch) * subset_prop)

set.seed(1)
for (i in 1:asw_repeat) {
  subset_index <- 
    data.frame(index = 1:length(batch) , batch = batch) %>%
    slice_sample(n = subset_size_total, replace = F)
  
  subset_id <- subset_index %>%
    pull(index)
  
  asw_batch_i <- silhouette(as.integer(factor(batches[subset_id])), dist(joint[subset_id, 1:npcs]))
  asw_batch[[i]] <- as.data.frame(rbind(summary(asw_batch_i)[["si.summary"]]))
  
  asw_group_i <- silhouette(as.integer(factor(groups[subset_id])), dist(joint[subset_id, 1:npcs]))
  asw_group[[i]] <- as.data.frame(rbind(summary(asw_group_i)[["si.summary"]]))
}

all_asw_batch <- bind_rows(asw_batch) %>%
  mutate(cluster = "Batch")

# ASW_batch summary
summary(all_asw_batch$Mean)

all_asw_group <- bind_rows(asw_group) %>%
  mutate(cluster = "Group")

#ASW_group summary
summary(all_asw_group$Mean)
```

### Calculate LISI Scores

```{r}
# Repeat LISI for sub-samples??
lisi_repeat <- 20
npcs <- 30

lisi_batch <- list()
lisi_group <- list()
subset_prop <- 0.8 # sub-sample to 80% of the data
subset_size_total <- floor(length(batch) * subset_prop)

set.seed(1)
for (i in 1:lisi_repeat) {
  subset_index <- 
    data.frame(index = 1:length(batch) , batch = batch) %>%
    slice_sample(n = subset_size_total, replace = F)
  
  subset_id <- subset_index %>%
    pull(index)
  
  lisi_batch[[i]] <- cbind(iter = i, compute_lisi(joint[subset_id, 1:npcs], data.frame(batch = batches[subset_id]), label_colnames = "batch"))
  lisi_group[[i]] <- cbind(iter = i, compute_lisi(joint[subset_id, 1:npcs], data.frame(group = groups[subset_id]), label_colnames = "group"))
}

all_lisi_batch <- bind_rows(lisi_batch)
summary(all_lisi_batch$batch) # Looking for values close to the number of batches (2)

all_lisi_group <- bind_rows(lisi_group)
summary(all_lisi_group$group) # Looking for values close to 1

####

# Performed for all cells
batch_lisi <- compute_lisi(joint, data.frame(batch = batches), label_colnames = "batch")
summary(batch_lisi)

group_lisi <- compute_lisi(joint, data.frame(group = groups), label_colnames = "group")
summary(group_lisi)
```


## Seurat

### Setup

```{r seurat_setup}
b1_seurat <- CreateSeuratObject(counts = b1, project = "simulation")
b1_seurat <- AddMetaData(b1_seurat, "Batch 1", col.name = "BatchNum")
b1_seurat <- AddMetaData(b1_seurat, grp_b1, col.name = "Group")

b2_seurat <- CreateSeuratObject(counts = b2, project = "simulation")
b2_seurat <- AddMetaData(b2_seurat, "Batch 2", col.name = "BatchNum")
b2_seurat <- AddMetaData(b2_seurat, grp_b2, col.name = "Group")

seurat_list <- list(Batch1 = b1_seurat, Batch2 = b2_seurat)

# normalize and identify variable features for each dataset independently
seurat_list <- lapply(X = seurat_list, FUN = function(x) {
    x <- NormalizeData(x)
    x <- FindVariableFeatures(x, selection.method = "vst", nfeatures = 2000)
})

# select features that are repeatedly variable across datasets for integration
features <- SelectIntegrationFeatures(object.list = seurat_list)
```

### Integration

```{r seurat_integration}
anchors <- FindIntegrationAnchors(object.list = seurat_list, anchor.features = features)
combined <- IntegrateData(anchorset = anchors)
GetAssay(combined, "integrated")
```

### Integrated Analysis

```{r seurat_integrated_analysis}
# specify that we will perform downstream analysis on the corrected data note that the
# original unmodified data still resides in the 'RNA' assay
DefaultAssay(combined) <- "integrated"

# Run the standard workflow for visualization and clustering
set.seed(1)
combined <- ScaleData(combined, verbose = FALSE)
combined <- RunPCA(combined, npcs = 30, verbose = FALSE)
# combined <- RunTSNE(combined, reduction = "pca", dims = 1:30)
# combined <- RunUMAP(combined, reduction = "pca", dims = 1:30)
```

```{r seurat_integrated_viz}
# Visualization
seurat_p1 <- DimPlot(combined, reduction = "pca", group.by = "BatchNum", shape.by = "Group")
seurat_p1
```

# Session Information

```{r session_info}
sessionInfo()
```
